# statapp

##  Python Version

D√©velopp√© avec:

```bash
Python 3.12.7
```
---

## Installer les d√©pendances

Depuis la racine du projet :

```bash
pip install -r requirements.txt
```

---

## Fichier `.env`

Pour faire marcher les diff√©rents codes, il faut cr√©er un fichier `.env` √† la racine du projet avec :

```env
GEMINI_API_KEY="votre_cl√©"
```

Vous pouvez voir un exemple dans le fichier `env_example.sh` 

---

## üß† √âvaluer un score de confiance avec les m√©thodes white-box

L‚Äôid√©e de cette partie du projet est de **mesurer la confiance du mod√®le** pour chaque r√©ponse en exploitant les **log-probabilit√©s des tokens** retourn√©es par Gemini.

## üìÅ Fichiers importants

- `white_box.py`  
  Contient la classe principale `UnifiedProbGeminiBatch` qui :
  - construit les prompts pour Gemini,
  - appelle l‚ÄôAPI avec `response_logprobs=True`,
  - parse le JSON de sortie,
  - extrait les tokens + logprobs,
  - calcule un score de confiance pour chaque r√©ponse.

- `main_whitebox.py`  
  Script en ligne de commande qui montre comment utiliser `UnifiedProbGeminiBatch` pour :
  - des r√©ponses bool√©ennes (`mode=bool`),
  - des r√©ponses num√©riques (`mode=float`),
  - des r√©ponses QCM (`mode=string`).

---

### Principe g√©n√©ral

1. On donne au mod√®le une liste de questions (*queries*).
2. On force la r√©ponse dans un format JSON strict :

   - Mode `bool` :

     ```json
     {"answers":[true,false,true]}
     ```

   - Mode `float` :

     ```json
     {"answers":[4.25,0.3333,0.015]}
     ```

   - Mode `string` (QCM) :

     ```json
     {"answers":["D","C","A"]}
     ```

3. `UnifiedProbGeminiBatch` parse ce JSON pour r√©cup√©rer la **valeur** de chaque r√©ponse.
4. En parall√®le, le code r√©cup√®re les **tokens choisis** et leurs **logprobs**.
5. En agr√©geant ces logprobs (en gros `exp(sum(logprobs))`), on obtient un **score de confiance** pour chaque r√©ponse.
6. Le script retourne pour chaque query un couple :

   ```text
   (valeur, probabilit√©)
   ```

---

## Comment lancer `main_whitebox.py`

### Mode bool√©en

Questions dont la r√©ponse attendue est `True` ou `False`.

```bash
python main_whitebox.py --mode bool
```

---

### Mode num√©rique (`float`)

Questions qui doivent renvoyer un **nombre**.

```bash
python main_whitebox.py --mode float
```

---

### Mode QCM (`string`)

Questions √† choix multiples o√π la r√©ponse est une lettre (`A`, `B`, `C`, `D`, ‚Ä¶).

```bash
python main_whitebox.py --mode string
```

Il suffit de changer les querries dans le fichier `main_whitebox.py` pour traiter d'autres exemples.
---

## Arguments disponibles

```bash
python main_whitebox.py   --mode {bool,float,string}   --model models/gemini-2.0-flash   --batch-size 16   --log-level INFO
```

---

## Format de sortie

Exemple d‚Äôaffichage :

```text
01. Is 7 * 8 equal to 56?
    ‚Üí (True, 0.998231)

02. Does 2^10 equal 1000?
    ‚Üí (False, 0.957221)
```

---



## Evaluer les phrases g√©n√©rer par un LLM (SelfCheckGPT)

Cette m√©thode suit l‚Äôesprit du papier **SelfCheckGPT (2023)** :  
un LLM joue le r√¥le de *juge* pour v√©rifier si une phrase est **support√©e** par un *ensemble de passages*.

Pour chaque phrase *s_i* et passage *p_j* :

- `true`  ‚Üí support√©  
- `false` ‚Üí non support√©  
- parse KO ‚Üí score neutre `0.5`

üëâ Le mod√®le doit r√©pondre **uniquement** :

```json
{"answers":[true,false,true,...]}
```

---


## üìÅ Fichiers importants

- `LLM_judge_gemini.py`  
  Contient la classe `SelfCheckGeminiBatch`.

- `main_LLM_judge.py`  
  Script permettant de lancer une √©valuation SelfCheck.

---

## Scores retourn√©s

- `1.0` si support√©  
- `0.0` si non support√©  
- `0.5` si ind√©termin√©  

Renvoie :

- `predict_matrix(sentences, passages)` ‚Üí matrice **M √ó K**
- `predict_mean(sentences, passages)` ‚Üí score moyen par phrase

---

## Exemple r√©aliste (inspir√© SelfCheckGPT)

Nous voulons v√©rifier si un mod√®le hallucine dans un r√©sum√© g√©n√©r√©.

### Phrases (r√©sum√© du mod√®le)

```text
1. The Eiffel Tower was completed in 1889.
2. The Eiffel Tower is 450 meters tall.
3. It was originally intended as a temporary structure.
4. It was designed by Antoni Gaud√≠.
```

### Passages (sources candidates)

```text
A. The Eiffel Tower, designed by Gustave Eiffel for the 1889 Exposition Universelle 
   in Paris, was completed the same year and quickly became a global symbol of France.

B. When it was built, the Eiffel Tower was initially intended to be dismantled after 
   twenty years. However, its usefulness as a radio transmission tower ensured its preservation.

C. The Eiffel Tower stands at approximately 324 meters tall, including its antenna. 
   It remained the tallest man-made structure in the world until 1930.

```

Ici :

- Phrase 1 ‚Üí support√©e (A)  
- Phrase 2 ‚Üí **non support√©e** car la tour ne fait pas 450m  
- Phrase 3 ‚Üí support√©e (B)  
- Phrase 4 ‚Üí **hallucination claire** (Gaud√≠ n‚Äôa rien √† voir)

---

## Lancer l‚Äôexemple SelfCheck

Ex√©cuter :

```bash
python main_LLM_judge.py
```

Ou avec param√®tres :

```bash
python main_LLM_judge.py --batch-size 16 --log-level INFO
```

---

##  Exemple de sortie attendue

```
=== Score matrix (M x K) ===
[[1. 0. 0.]
 [0. 0. 0.]
 [0. 1. 0.]
 [0. 0. 0.]]

=== Mean score per sentence ===
[0.33   0.   0.33 0.  ]

- The Eiffel Tower was completed in 1889.
  score=0.333

- The Eiffel Tower is 450 meters tall.
  score=0.000

- It was originally intended as a temporary structure.
  score=0.333

- It was designed by Antoni Gaud√≠.
  score=0.000
```


